{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import server_local, server_prod\n",
    "from src.utils.helper import check_response_status, parse_sse\n",
    "import requests\n",
    "\n",
    "server = server_local\n",
    "print(server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a horse.\"\n",
    "user_prompt = \"Hello, World!\"\n",
    "\n",
    "\n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "data = {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"call_openai\"\n",
    "\n",
    "response = requests.post(f\"{server}/{endpoint}\", json=data, stream=True)\n",
    "check_response_status(response)\n",
    "events = parse_sse(response)\n",
    "\n",
    "for event_data in events:\n",
    "    print(event_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    endpoint = \"gen_uuid\"\n",
    "\n",
    "    response = requests.post(f\"{server}/{endpoint}\", json=data, stream=True)\n",
    "    check_response_status(response)\n",
    "    events = parse_sse(response)\n",
    "\n",
    "    for event in events:\n",
    "        print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "parallel_requests = 640\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=parallel_requests) as executor:\n",
    "    # Pass the function reference, not the result\n",
    "    futures = [executor.submit(main) for _ in range(parallel_requests)]\n",
    "\n",
    "    # Wait for all to complete if needed\n",
    "    for future in futures:\n",
    "        future.result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
